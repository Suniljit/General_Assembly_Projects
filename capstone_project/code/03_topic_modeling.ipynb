{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7f9ea4-ebc7-4541-af5d-7c8cbc1b33a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Capstone Project: Topic Modelling of Academic Journals (Model-Based Systems Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c83ece-a75d-420a-8d38-cb74fd6d54ed",
   "metadata": {},
   "source": [
    "# 03: Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a31e9-0188-4cca-a174-1b3542a4e068",
   "metadata": {},
   "source": [
    "In this notebook, we will perform the following actions:\n",
    "1. Topic Modelling\n",
    "2. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdff992-4c67-4de1-b296-a6d81278244b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a526d9e3-e212-4099-b622-5ef395e395e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/dsi-sg/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/Caskroom/miniconda/base/envs/dsi-sg/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/Caskroom/miniconda/base/envs/dsi-sg/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/Caskroom/miniconda/base/envs/dsi-sg/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "#from bertopic import BERTopic\n",
    "from gensim.models import HdpModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import dense2vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set all columns and rows to be displayed\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52287f4-adc2-46f5-bccf-d637abf71afb",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9851fb-181e-4cb5-aac6-00194d1f24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data for modelling\n",
    "journals = pd.read_csv('../data/journals_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ea8fe-636b-4694-9c22-894195087725",
   "metadata": {},
   "source": [
    "## Final Data Preprocessing using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83e72e-2214-4699-8b3f-deadfe2cf219",
   "metadata": {},
   "source": [
    "In this section, we will perform our final data preprocessing using TF-IDF (Term Frequency - Inverse Document Frequency). TF-IDF is used as it takes into account how often a word appears in the whole corpus. This helps to penalize common words that appear across every document, which is not informative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32fd35f-3c13-405b-870a-c213f1975eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a TF-IDF Vectorizer\n",
    "tvec_journals = TfidfVectorizer(lowercase=False, ngram_range=(1,3))\n",
    "\n",
    "# Fit and transform the text data to prepare for topic modelling\n",
    "journals_corpus = tvec_journals.fit_transform(journals['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25b21c-c555-4898-823c-a9337e995a5b",
   "metadata": {},
   "source": [
    "## Topic Modelling using Latent Dirichlet Allocation (LDA) - sklearn implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0c9dc-f466-43f3-852b-d1cf3e0c79e0",
   "metadata": {},
   "source": [
    "Here, we will perform topic modelling using LDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bc0802-f065-4e91-bdc0-49ed6edae15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=7, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=7,\n",
    "                                     random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lda_model.fit(journals_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27af1838-7881-4385-8069-41279f8fcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "data digital new safety support study methodology level case need\n",
      "\n",
      "Topic #1:\n",
      "domain concept work study mission space cost research application integration\n",
      "\n",
      "Topic #2:\n",
      "mission methodology validation new domain verification level based activity data\n",
      "\n",
      "Topic #3:\n",
      "safety industry different methodology level case engineer need opm chapter\n",
      "\n",
      "Topic #4:\n",
      "safety concept transformation research work document change data integration methodology\n",
      "\n",
      "Topic #5:\n",
      "domain challenge application new slim support present phase integration problem\n",
      "\n",
      "Topic #6:\n",
      "support data integrated safety software challenge document capability different digital\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the top words for each topic\n",
    "feature_names = tvec_journals.get_feature_names_out()\n",
    "n_top_words = 10\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    print(\"Topic #%d:\" %topic_idx)\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words -1:-1]]))\n",
    "    print()\n",
    "    \n",
    "# Extract the topic distribution for each journal\n",
    "journal_topic_dist = lda_model.transform(journals_corpus)\n",
    "\n",
    "# Create a dataframe to store the journal topics probability distribution\n",
    "df_journal_topic_dist = pd.DataFrame(journal_topic_dist, columns=['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6'])\n",
    "\n",
    "# Add in a column with the topic generated \n",
    "df_journal_topic_dist['topic_generated'] = journal_topic_dist.argmax(axis=1)\n",
    "\n",
    "# Add in the title of the journal\n",
    "df_journal_topic_dist['title'] = journals['title']\n",
    "\n",
    "# Add in the publication year of each journal\n",
    "df_journal_topic_dist['year'] = journals['year'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a73c916-3e65-4cf7-8fee-265b16c8ea97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_generated</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.931773</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.011368</td>\n",
       "      <td>2</td>\n",
       "      <td>Model-based Design Process for the Early Phase...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.937874</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>2</td>\n",
       "      <td>Model Based Systems Engineering using VHDL-AMS</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010191</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.938895</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>4</td>\n",
       "      <td>Code Generation Approach Supporting Complex Sy...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.947089</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>4</td>\n",
       "      <td>Model based systems engineering as enabler for...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.936519</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>2</td>\n",
       "      <td>Electric Drive Vehicle Development and Evaluat...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
       "0  0.011376  0.011372  0.931773  0.011371  0.011373  0.011367  0.011368   \n",
       "1  0.010357  0.010352  0.937874  0.010357  0.010355  0.010352  0.010353   \n",
       "2  0.010191  0.010183  0.010192  0.010179  0.938895  0.010180  0.010179   \n",
       "3  0.008825  0.008819  0.008814  0.008818  0.947089  0.008816  0.008818   \n",
       "4  0.010582  0.010585  0.936519  0.010576  0.010584  0.010577  0.010577   \n",
       "\n",
       "   topic_generated                                              title  year  \n",
       "0                2  Model-based Design Process for the Early Phase...  2017  \n",
       "1                2     Model Based Systems Engineering using VHDL-AMS  2013  \n",
       "2                4  Code Generation Approach Supporting Complex Sy...  2022  \n",
       "3                4  Model based systems engineering as enabler for...  2021  \n",
       "4                2  Electric Drive Vehicle Development and Evaluat...  2014  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_journal_topic_dist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b2e44-c164-4af5-b15d-1aa59a50b0ce",
   "metadata": {},
   "source": [
    "## Topic Modeling using Hierarchical Dirichlet Process (HDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3173d44-0935-4d79-996a-2b2009bd9dbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [('exmc', 9.693473614367421e-05), ('spacecraft mission ever', 9.546788112991308e-05), ('medical', 9.456319869202603e-05), ('field predominantly focus', 8.393760888049093e-05), ('air sea', 7.411506315889563e-05), ('increasingly consequently', 7.36843600943108e-05), ('simulator enables', 7.061182728569595e-05), ('substitute substantial', 6.963797047861733e-05), ('evaluated scope innovation', 6.688301040198796e-05), ('still difficult task', 6.530436244694119e-05), ('optimization', 6.527950878551754e-05), ('element report review', 6.502066619295586e-05), ('integrating three', 6.473781853249864e-05), ('component subsystem could', 6.444382097774067e-05), ('better understanding behavior', 6.39179245668562e-05), ('challenging implemented', 6.26660399442616e-05), ('modeled posse always', 6.13289641878113e-05), ('potential major', 6.0728657229594897e-05), ('connecting data', 5.941921818044092e-05), ('relation main concept', 5.870820859662418e-05)])\n",
      "(1, [('rts', 9.112087889380139e-05), ('compared literature', 7.99361018260753e-05), ('account', 7.573714364520556e-05), ('test', 7.440874206180241e-05), ('level expectation adopting', 7.395986663426712e-05), ('configurable verification', 7.382507822084993e-05), ('simulate implement swarm', 7.101751093251837e-05), ('los', 7.06477659377034e-05), ('definition established', 7.044496842303742e-05), ('reliability', 6.983603786552197e-05), ('facility facility', 6.922379981296854e-05), ('view', 6.801089520872173e-05), ('function embodiment', 6.674781854761087e-05), ('engineer problem', 6.558924589471512e-05), ('digitalization communication interconnection', 6.415260941189403e-05), ('specialty group', 6.40587730585851e-05), ('service', 6.249508908205134e-05), ('independently include', 6.138824585902943e-05), ('customer future', 6.038452825834471e-05), ('functionality component considered', 6.0162423704951405e-05)])\n",
      "(2, [('linked', 0.00010285663073459605), ('human', 9.351578052542369e-05), ('diagram unfortunately', 7.705026947859869e-05), ('right', 7.511780358322852e-05), ('library', 7.252826060837363e-05), ('consistency functional proposed', 7.16958418114945e-05), ('reliability', 6.9996607691841e-05), ('needed leverage', 6.583699938559392e-05), ('concept automate practice', 6.443697323594999e-05), ('diagram ipssa modelling', 6.412347102156098e-05), ('sustainment procedure', 6.366599856650862e-05), ('production cell', 6.348186312295215e-05), ('coherent', 6.328435141627982e-05), ('locally production due', 6.178482094503815e-05), ('aim investigate', 6.154631440149805e-05), ('component', 6.136990655676408e-05), ('along possible', 6.121165124740969e-05), ('cps', 6.0909227207170446e-05), ('functional innovative', 6.042075113695132e-05), ('matrix report', 6.041179304413518e-05)])\n",
      "(3, [('transitioning real', 7.539780279520738e-05), ('delivery efficient', 7.249000315510897e-05), ('lifespan particular', 6.626447080312464e-05), ('expected behavior specified', 6.52615203579856e-05), ('application methodology', 6.477383879846862e-05), ('share form digital', 6.439971857325182e-05), ('component', 6.263264466872942e-05), ('of interest included', 6.258450868693659e-05), ('query engine numerical', 6.144065173490745e-05), ('time specialty domain', 6.143049910780601e-05), ('ab hence rapidly', 6.133882172851763e-05), ('oriented artifact relation', 6.109844606710272e-05), ('formalize domain specific', 5.9878281369488233e-05), ('recycling company', 5.884403644656557e-05), ('element relation allows', 5.8680259967226444e-05), ('early stage activity', 5.8333071773373464e-05), ('survey propose prioritization', 5.7915050375795376e-05), ('environment discipline multiple', 5.687884971825092e-05), ('definition change', 5.6781090924633685e-05), ('found independent satellite', 5.6305332326418375e-05)])\n",
      "(4, [('opm', 9.664173996634814e-05), ('cps high granularity', 7.916412950568392e-05), ('weapon', 7.354505943432054e-05), ('peer', 7.076225801937447e-05), ('offering fulfilling customer', 6.688936142404225e-05), ('forward qualitative capability', 6.623198125486179e-05), ('begun implemented many', 6.588970248197731e-05), ('methodology accordance', 6.521269919460308e-05), ('exemplified syndeia mbe', 6.468676597559317e-05), ('benefit result', 6.40631050712396e-05), ('touch even', 6.376877407226943e-05), ('practises applies', 6.36101997503462e-05), ('engineer check interoperability', 6.262607442132681e-05), ('research proposes industrial', 6.21758711046449e-05), ('recent year present', 6.197291981797229e-05), ('phase presently opscon', 6.177550655024679e-05), ('wsaf', 6.101658475754382e-05), ('related technique', 6.092039631350595e-05), ('studying impact coming', 6.0319288055120877e-05), ('implemented query view', 5.973780515120738e-05)])\n"
     ]
    }
   ],
   "source": [
    "# Convert the vectorized data into a Gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(journals_corpus, documents_columns=False)\n",
    "\n",
    "# Create a dictionary from the corpus\n",
    "id2word = Dictionary.from_corpus(corpus, id2word=dict((id, word) for word, id in tvec_journals.vocabulary_.items()))\n",
    "\n",
    "# Train the HDP model\n",
    "hdp_model = HdpModel(corpus=corpus, id2word=id2word)\n",
    "\n",
    "# Print the topics\n",
    "topics = hdp_model.show_topics(num_topics=5,formatted=False)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502c04b-88a4-4868-b1bd-0b74cac8e31a",
   "metadata": {},
   "source": [
    "The HDP model does not seem to be very helpful, as it outputs a total of 150 topics. Meaning each topic is assigned approximately 5-6 articles. Furthermore, each keyword for each topic only has a 0.1% or less probability of being associated to the topic. This does not allow us to gain much insight. Hence, we will not be using the HDP model.\n",
    "*The total number of topics generated can be seen by adjusting the num_topics hyperparameter above to 200. You will observe that 150 topics will be generated.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f1bc39-3895-4747-9db4-8828af55ff4b",
   "metadata": {},
   "source": [
    "## Topic Modeling using BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00613e79-3d0a-4fae-9063-3dc6f081e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a BERTopic model\n",
    "bertopic_model = BERTopic()\n",
    "\n",
    "# Fit and transform the model to the corpus\n",
    "topics, _ = bertopic_model.fit_transform(journals['tokens'])\n",
    "\n",
    "# Print the top words for each topic\n",
    "for topic_id in range(max(topics)):\n",
    "    words = bertopic_model.get_topic(topic_id)\n",
    "    print(f\"Topic {topic_id}: {' | '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d971f18-8d71-4e0b-8cf7-f99e77cdfbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae4c2657-43b0-4581-9a3f-dba6d2dbb507",
   "metadata": {},
   "source": [
    "## Topic Modelling using Latent Dirichlet Allocation (LDA) - gensim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f2ba4-4086-4c6c-8285-1dd3df1317cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert corpus to Gensim format\n",
    "corpus = gensim.matutils.Sparse2Corpus(journals_corpus, documents_columns=False)\n",
    "\n",
    "# Create Gensim dictionary\n",
    "id2word = Dictionary.from_corpus(corpus, id2word=dict((id, word) for word, id in tvec_journals.vocabulary_.items()))\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=id2word,\n",
    "                     num_topics=5,\n",
    "                     random_state=42,\n",
    "                     passes=10)\n",
    "\n",
    "# Print keywords for each topic\n",
    "for idx, topic in lda_model.show_topics(num_topics=5, num_words=15, formatted=False):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, [w[0] for w in topic]))\n",
    "\n",
    "# Create dataframe with topic probabilities for each document\n",
    "topic_probs = [lda_model.get_document_topics(corpus[i]) for i in range(len(corpus))]\n",
    "df_topic_probs = pd.DataFrame([{f'topic_{tp[0]}': tp[1] for tp in probs} for probs in topic_probs])\n",
    "\n",
    "# Combine topic probabilities dataframe with original data\n",
    "df_journals_gensim = pd.concat([data, df_topic_probs], axis=1)\n",
    "\n",
    "# Add column for topic with highest percentage\n",
    "df_journals_gensim['topic_generated'] = df_journals_gensim.iloc[:, 3:].idxmax(axis=1)\n",
    "\n",
    "# Add in the title of the journal\n",
    "df_journals_gensim['title'] = journals['title']\n",
    "\n",
    "# Add in the publication year of each journal\n",
    "df_journals_gensim['year'] = journals['year'] \n",
    "\n",
    "# Frop the sentences column\n",
    "df_journals_gensim.drop(columns='sentences', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eff133-354a-4d3c-95e8-21ffac602652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals_gensim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e605d4-c33c-4f3c-a3ce-a3addcab7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journals_gensim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d730bd-9339-4ea4-aa54-52caced19f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81021b-d8b7-49f1-9df4-2aa068d88b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1882d-093c-4e75-87d5-fe891b44764c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92cb6f-04d5-4dbe-b8ca-1fbc4a95cce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8d076-35fa-41ae-b3dc-23f8dfafe5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffde2e-c633-4ad2-82ca-6e8355841bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "389ce986-0315-4364-9763-7b7c17575fbc",
   "metadata": {},
   "source": [
    "# Outstanding Work\n",
    "* Do EDA on the year distribution of the articles\n",
    "* Fine tune the stop words to make the keywords in each topic distinct\n",
    "* Evaluate the key words and create a proper topic label using domain knowledge and reading the top few articles for each topic\n",
    "* Topic evaluation with visualizations, distributions and trending\n",
    "* Recommendations for the organization\n",
    "* Classficiation models for future articles\n",
    "* Create dashboard\n",
    "* Touch up on the EDA for presentation slides\n",
    "* Create slides and prepare for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716ccba-35d4-46fc-9014-5aaff7bf68af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ec3e6-41f9-4456-a23f-dcc9d7bbf6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fee6a9-fe9b-4f53-a0bb-1f502e447c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8651475-e296-43d2-afa3-dd4fdcc9219c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e49b3c-97c6-4bac-889e-7e026b5943f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbda441-4d4a-4536-9a96-b12accbf823c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a0068-7639-4373-868f-48b21b5e4b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad2917-6e46-41b5-bb94-056f755719eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faab46c-0334-42fb-9dff-5ea0d814e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290f4f1-c9e0-4875-9d0d-0a0d64b22418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi-sg",
   "language": "python",
   "name": "dsi-sg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
